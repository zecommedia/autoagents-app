# ğŸ¯ Chat Mode Implementation Guide

Dá»±a trÃªn phÃ¢n tÃ­ch tá»« **AutoAgents-Redesign/App.tsx**, Ä‘Ã¢y lÃ  hÆ°á»›ng dáº«n chi tiáº¿t Ä‘á»ƒ cáº£i tiáº¿n Chat Mode trong autoagents-app.

---

## ğŸ“Š So sÃ¡nh Architecture

### **AutoAgents-Redesign** (Tá»‘t hÆ¡n)
```
executeChatTurn()
â”œâ”€â”€ OpenAI Path
â”‚   â”œâ”€â”€ CASE 1: Text-only chat â†’ GPT-4o-mini streaming
â”‚   â”œâ”€â”€ CASE 2: Image generation â†’ DALL-E 3
â”‚   â”œâ”€â”€ CASE 3: 1 image edit â†’ DALL-E 2 Edit
â”‚   â””â”€â”€ CASE 4: 2+ images â†’ Warning message
â”‚
â””â”€â”€ Gemini Path
    â”œâ”€â”€ IMAGE MODE: 1 or 2 images with text
    â”‚   â”œâ”€â”€ 1 image â†’ Gemini function call (editImage)
    â”‚   â”œâ”€â”€ 2 images â†’ Warning message
    â”‚   â””â”€â”€ 3+ images â†’ Error
    â””â”€â”€ TEXT MODE: No images
        â””â”€â”€ Gemini streaming with function calls
```

### **autoagents-app** (Hiá»‡n táº¡i - Cáº§n cáº£i tiáº¿n)
```
executeChatTurn()
â”œâ”€â”€ OpenAI Path
â”‚   â”œâ”€â”€ hasImage check (khÃ´ng Ä‘áº¿m sá»‘ áº£nh)
â”‚   â”œâ”€â”€ wantsImageGen check
â”‚   â”œâ”€â”€ Chat with image_url parts (streaming)
â”‚   â””â”€â”€ KhÃ´ng handle multi-image
â”‚
â””â”€â”€ Gemini Path
    â”œâ”€â”€ Sá»­ dá»¥ng Cloud API
    â”œâ”€â”€ Detect áº£nh Ä‘Æ¡n
    â””â”€â”€ ChÆ°a handle 2 áº£nh cÃ¹ng lÃºc
```

---

## ğŸ”§ CÃ¡c thay Ä‘á»•i cáº§n thá»±c hiá»‡n

### **Change 1: Improve image counting (OpenAI)**

**Location**: `src/App.tsx`, function `executeChatTurn`, line ~730

**Current Code**:
```typescript
const hasImage = currentUserParts.some(p => 'inlineData' in p);
const textInPrompt = currentUserParts.filter((p: any) => p.text).map((p: any) => p.text).join(' ').trim();
const wantsImageGen = !hasImage && /\b(generate|create|draw...)\.test(textInPrompt);
```

**New Code**:
```typescript
// Count images properly
const imageParts = currentUserParts.filter(p => 'inlineData' in p);
const textPart = currentUserParts.find(p => 'text' in p);
const textInPrompt = textPart?.text || '';
const wantsImageGen = imageParts.length === 0 && /\b(generate|create|draw|váº½|táº¡o áº£nh|tao anh|táº¡o hÃ¬nh|tao hinh|táº¡o|ve)\b/i.test(textInPrompt);
```

**Benefit**: Biáº¿t chÃ­nh xÃ¡c cÃ³ bao nhiÃªu áº£nh (0, 1, 2, 3+)

---

### **Change 2: Add multi-image warning (OpenAI)**

**Location**: Sau pháº§n xá»­ lÃ½ single image edit trong OpenAI path

**Add this code BEFORE the text-only chat streaming logic**:
```typescript
// CASE 4: Multi-image (2 images) - Not supported
if (imageParts.length === 2) {
    setChatHistory(prev => {
        const newHistory = [...prev];
        newHistory[modelResponseIndex] = {
            role: 'model',
            parts: [{ 
                text: `âš ï¸ Multi-image editing detected! Currently only single image editing is supported in Chat mode.\n\nPlease use:\n- **Clone mode** for combining 2 images\n- Or send images one at a time` 
            }],
            provider
        };
        return newHistory;
    });
    return;
}

// Too many images
if (imageParts.length > 2) {
    throw new Error('Too many images. Maximum 2 images supported.');
}
```

---

### **Change 3: Improve Gemini image handling**

**Location**: `src/App.tsx`, function `executeChatTurn`, Gemini path (~line 850)

**Current flow**:
```typescript
if (provider === 'gemini') {
    try {
        // Check if user sent images + text
        const imageParts = currentUserParts.filter(p => 'inlineData' in p);
        const textPart = currentUserParts.find(p => 'text' in p);
        
        if (imageParts.length > 0 && textPart) {
            // Single image edit
            ...
        }
        
        // Text-only chat
        ...
    }
}
```

**Improved flow**:
```typescript
if (provider === 'gemini') {
    try {
        const imageParts = currentUserParts.filter(p => 'inlineData' in p);
        const textPart = currentUserParts.find(p => 'text' in p);
        
        // IMAGE EDITING MODE (1 or 2 images)
        if (imageParts.length > 0 && textPart) {
            console.log(`ğŸ–¼ï¸ Gemini Image Edit Mode - ${imageParts.length} image(s)`);
            
            if (imageParts.length === 1) {
                // SINGLE IMAGE EDIT
                const dataUrl = `data:${imageParts[0].inlineData.mimeType};base64,${imageParts[0].inlineData.data}`;
                const resultImageBase64 = await generateImageViaCloudApi(dataUrl, textPart.text, 'edit', 'gemini');
                
                let imageBase64 = resultImageBase64;
                if (typeof resultImageBase64 === 'string' && resultImageBase64.includes(',')) {
                    imageBase64 = resultImageBase64.split(',')[1];
                }
                
                setChatHistory(prev => {
                    const newHistory = [...prev];
                    newHistory[modelResponseIndex] = {
                        role: 'model',
                        parts: [
                            { text: `ÄÃ¢y lÃ  áº£nh Ä‘Ã£ chá»‰nh sá»­a:` },
                            { inlineData: { data: imageBase64, mimeType: 'image/png' } }
                        ],
                        provider
                    };
                    return newHistory;
                });
            } else if (imageParts.length === 2) {
                // MULTI-IMAGE: Show warning
                setChatHistory(prev => {
                    const newHistory = [...prev];
                    newHistory[modelResponseIndex] = {
                        role: 'model',
                        parts: [{ 
                            text: `âš ï¸ Multi-image editing detected! Currently only single image editing is supported in Chat mode.\n\nPlease use:\n- **Clone mode** for combining 2 images\n- Or send images one at a time` 
                        }],
                        provider
                    };
                    return newHistory;
                });
            } else {
                throw new Error('Too many images. Maximum 2 images supported.');
            }
            
            return; // Exit early after image editing
        }
        
        // TEXT-ONLY CHAT MODE continues...
        const messages = historySoFar.map(msg => ({
            role: msg.role === 'user' ? 'user' : 'assistant',
            content: msg.parts.map((p: any) => {
                if ('text' in p) return p.text;
                if ('inlineData' in p) return '[Image]';
                return '';
            }).join(' ')
        }));
        
        const currentText = currentUserParts
            .filter((p: any) => 'text' in p)
            .map((p: any) => p.text)
            .join(' ');
        
        messages.push({ role: 'user', content: currentText });

        const result = await cloudApiService.chat(messages, 'gemini');
        
        if (!result.success) {
            throw new Error(result.error || 'Chat failed');
        }

        const responseText = result.data?.data || result.data || '';
        
        setChatHistory(prev => {
            const newHistory = [...prev];
            newHistory[modelResponseIndex] = {
                role: 'model',
                parts: [{ text: responseText }],
                provider
            };
            return newHistory;
        });
    } catch (error: any) {
        console.error("Gemini chat via Cloud API failed:", error);
        setChatHistory(prev => {
            const newHistory = [...prev];
            newHistory[modelResponseIndex] = {
                role: 'model',
                parts: [{ text: `Sorry, chat failed: ${error.message || 'Unknown error'}` }],
                provider
            };
            return newHistory;
        });
    }
    return;
}
```

---

## ğŸ“‹ Step-by-Step Implementation

### Step 1: Backup current file
```bash
cp src/App.tsx src/App.tsx.backup
```

### Step 2: Apply Change 1 (Image counting)
TÃ¬m dÃ²ng:
```typescript
const hasImage = currentUserParts.some(p => 'inlineData' in p);
```

Thay tháº¿ báº±ng:
```typescript
const imageParts = currentUserParts.filter(p => 'inlineData' in p);
const textPart = currentUserParts.find(p => 'text' in p);
const textInPrompt = textPart?.text || '';
const wantsImageGen = imageParts.length === 0 && /\b(generate|create|draw|váº½|táº¡o áº£nh|tao anh|táº¡o hÃ¬nh|tao hinh|táº¡o|ve)\b/i.test(textInPrompt);
```

Update all references:
- `hasImage` â†’ `imageParts.length > 0`
- `imageUrls` â†’ use `imageParts` directly

### Step 3: Apply Change 2 (Multi-image warning for OpenAI)
TÃ¬m pháº§n xá»­ lÃ½ OpenAI image edit, sau Ä‘Ã³ thÃªm case 4.

### Step 4: Apply Change 3 (Gemini improvements)
Cáº­p nháº­t pháº§n Gemini path nhÆ° code á»Ÿ trÃªn.

### Step 5: Test
```bash
npm run dev
```

Test cases:
1. âœ… OpenAI: Text-only
2. âœ… OpenAI: "generate a cat"
3. âœ… OpenAI: 1 image + text
4. âœ… OpenAI: 2 images â†’ warning
5. âœ… Gemini: Text-only
6. âœ… Gemini: 1 image + text
7. âœ… Gemini: 2 images â†’ warning

---

## ğŸ¯ Expected Results

### Before (Current)
- âŒ KhÃ´ng phÃ¡t hiá»‡n Ä‘Æ°á»£c 2 áº£nh
- âŒ NgÆ°á»i dÃ¹ng confuse khi gá»­i 2 áº£nh
- âŒ KhÃ´ng cÃ³ hÆ°á»›ng dáº«n rÃµ rÃ ng

### After (Improved)
- âœ… PhÃ¡t hiá»‡n chÃ­nh xÃ¡c sá»‘ lÆ°á»£ng áº£nh
- âœ… Hiá»ƒn thá»‹ warning message há»¯u Ã­ch
- âœ… HÆ°á»›ng dáº«n ngÆ°á»i dÃ¹ng sá»­ dá»¥ng Clone mode
- âœ… Code rÃµ rÃ ng, dá»… maintain
- âœ… Consistent vá»›i AutoAgents-Redesign

---

## ğŸ“š References

- **AutoAgents-Redesign/App.tsx**: Lines 596-880 (executeChatTurn function)
- **Key patterns**: Multi-image detection, provider separation, user guidance
